{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "from osgeo import gdal\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.auth import HTTPBasicAuth\n",
    "# import dotenv\n",
    "# dotenv.load_dotenv(dotenv.find_dotenv()) #.env file in the same directory as this script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This script is intended to download MODIS data from the LP DAAC archive.\n",
    "> The files to be downloaded are .hdf files.  In this notebook I am trying to download MODIS ET and PET (MOD16A2GF.061). (https://e4ftl01.cr.usgs.gov/MOLT/MOD16A2GF.061/)\n",
    "> Each hdf file contains both of these variables and the files are in timestamped folders.\n",
    "> To download the data, one needs an earthdata login so I have provided my credentials to authorize my access\n",
    "> The Problem is the code can find the files but I cant download them. I have confirmed that the my login is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code needs to be fixed so that it works!!! It does not download any files!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reference: https://github.com/bpostance/learn_data_engineering/blob/main/earth.observation/modis/MCD64A1v061-burned-areas/00.ETL-MODIS.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earth data login credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params fo LP DAAC\n",
    "# you will require an EarthData login\n",
    "host = fr'https://e4ftl01.cr.usgs.gov/MOLT/MOD16A2GF.061'\n",
    "login = 'Katoria'\n",
    "password = 'Firstclass0902'\n",
    "\n",
    "outDir = \"D:/tmp/KaToRiA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1104 folders found\n"
     ]
    }
   ],
   "source": [
    "# list folders from which to download\n",
    "r = requests.get(host, verify=True, stream=True,auth=(login,password))\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "folders = list()\n",
    "for link in soup.findAll('a', attrs={'href': re.compile(\"\\d{4}.\\d{2}.\\d{2}/\")}): #e.g. 2000.03.05/\n",
    "    folders.append(link.get('href'))\n",
    "print(f\"{len(folders)} folders found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283 files found in folder n\n"
     ]
    }
   ],
   "source": [
    "# list files in folders\n",
    "for f in folders[:1]:\n",
    "    file_list = list()\n",
    "    folder_url = f\"{host}/{f}\"\n",
    "    r = requests.get(folder_url, verify=True, stream=True,auth=(login,password))\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    for link in soup.findAll('a', attrs={'href': re.compile(\".hdf$\")}):\n",
    "        file_list.append(link.get('href'))    \n",
    "print(f\"{len(file_list)} files found in folder n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MOD16A2GF.A2000001.h21v08.061.2020256104621.hdf', 'MOD16A2GF.A2000001.h21v09.061.2020256103437.hdf', 'MOD16A2GF.A2000001.h22v08.061.2020256103529.hdf', 'MOD16A2GF.A2000001.h22v09.061.2020256103517.hdf']\n",
      "4 KENYA tiles found\n"
     ]
    }
   ],
   "source": [
    "# Since MODIS data is stored in numbered grids, select tiles corresponding to areas of interest.\n",
    "#Kenya lies in 4 grids: h21v08, h22v08, h21v09, h22v09 so select only these tiles for download.\n",
    "# https://modis-land.gsfc.nasa.gov/MODLAND_grid.html\n",
    "hreg = re.compile(\"h21|h22\") # Kenya is in h21 and h22\n",
    "vreg = re.compile(\"v0[8-9]\") # Kenya is in v08 and v09\n",
    "ken_files = list()\n",
    "for fl in file_list:\n",
    "    h = hreg.search(fl)\n",
    "    if h:\n",
    "        v = vreg.search(h.string)\n",
    "        if v:\n",
    "            ken_files.append(v.string)\n",
    "print(ken_files)\n",
    "print(f\"{len(ken_files)} KENYA tiles found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code works fine (or so I think up to here)\n",
    "> In the next cell it fails to download the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000.01.01/\n",
      "Request successful, downloading to D:/tmp/KaToRiA/MOD16A2GF.A2000001.h21v08.061.2020256104621.hdf\n",
      "Downloaded https://e4ftl01.cr.usgs.gov/MOLT/MOD16A2GF.061/2000.01.01/MOD16A2GF.A2000001.h21v08.061.2020256104621.hdf\n",
      "2000.01.01/\n",
      "Request successful, downloading to D:/tmp/KaToRiA/MOD16A2GF.A2000001.h21v09.061.2020256103437.hdf\n",
      "Downloaded https://e4ftl01.cr.usgs.gov/MOLT/MOD16A2GF.061/2000.01.01/MOD16A2GF.A2000001.h21v09.061.2020256103437.hdf\n",
      "2000.01.01/\n",
      "Request successful, downloading to D:/tmp/KaToRiA/MOD16A2GF.A2000001.h22v08.061.2020256103529.hdf\n",
      "Downloaded https://e4ftl01.cr.usgs.gov/MOLT/MOD16A2GF.061/2000.01.01/MOD16A2GF.A2000001.h22v08.061.2020256103529.hdf\n",
      "2000.01.01/\n",
      "Request successful, downloading to D:/tmp/KaToRiA/MOD16A2GF.A2000001.h22v09.061.2020256103517.hdf\n",
      "Downloaded https://e4ftl01.cr.usgs.gov/MOLT/MOD16A2GF.061/2000.01.01/MOD16A2GF.A2000001.h22v09.061.2020256103517.hdf\n"
     ]
    }
   ],
   "source": [
    "class SessionWithHeaderRedirection(requests.Session):\n",
    "    AUTH_HOST = 'urs.earthdata.nasa.gov'\n",
    "    \n",
    "    def __init__(self, username, password):\n",
    "        super().__init__()\n",
    "        self.auth = (username, password)\n",
    "\n",
    "    def rebuild_auth(self, prepared_request, response):\n",
    "        headers = prepared_request.headers\n",
    "        url = prepared_request.url\n",
    "        if 'Authorization' in headers:\n",
    "            original_parsed = requests.utils.urlparse(response.request.url)\n",
    "            redirect_parsed = requests.utils.urlparse(url)\n",
    "            if (original_parsed.hostname != redirect_parsed.hostname) and \\\n",
    "                    redirect_parsed.hostname != self.AUTH_HOST and \\\n",
    "                    original_parsed.hostname != self.AUTH_HOST:\n",
    "                del headers['Authorization']\n",
    "\n",
    "\n",
    "session = SessionWithHeaderRedirection(login, password)\n",
    "\n",
    "for f in folders[:1]:\n",
    "    for fl in ken_files[:]:\n",
    "        try:\n",
    "            file_url = f\"{host}/{f}{fl}\"\n",
    "            response = session.get(file_url, stream=True)\n",
    "\n",
    "            if response.ok:\n",
    "                if not os.path.exists(f\"{outDir}\"): os.makedirs(f\"{outDir}\")\n",
    "                print('Request successful, downloading to ' + f\"{outDir}/{fl}\")\n",
    "                with open(f\"{outDir}/{fl}\", 'wb') as fL:\n",
    "                    for chunk in response.iter_content(chunk_size=1024*1024): fL.write(chunk)\n",
    "                \n",
    "                print(f\"Downloaded {file_url}\")\n",
    "                time.sleep(4) # be nice to the server\n",
    "            elif response.status_code == 404:\n",
    "                print(f\"File not found: {file_url}\")\n",
    "            elif response.status_code == 401:\n",
    "                print(f\"Unauthorized access: {file_url}\")\n",
    "            else:\n",
    "                print('Request failed: ', response.text)\n",
    "\n",
    "        except: print(f\"Muhahahahahahaha! Error!: {fl}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multipurpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
